## Что такое QUIC?

Почему это так важно? Какая разница, HTTP/3 это делает или QUIC? Мне кажется, разница есть, ведь **QUIC — это универсальный транспортный протокол**. Как и TCP, он может и будет использоваться в разных сценариях, не только для HTTP и загрузки сайтов. Например, поверх QUIC можно пристроить DNS, SSH, SMB, RTP и так далее. Давайте узнаем о QUIC чуть больше, ведь именно с ним связаны многие заблуждения по поводу HTTP/3.

Вы, наверное, слышали, что QUIC работает поверх ещё одного протокола — _UDP_. Это правда, но производительность тут ни при чём. В идеале QUIC мог бы быть полностью независимым транспортным протоколом сразу над IP в стеке, как на картинке выше.

Но тогда возникли бы те же сложности, что и при попытке развивать TCP: пришлось бы сначала обновить все устройства в интернете, чтобы они распознавали и разрешали QUIC. К счастью, мы можем разместить QUIC поверх ещё одного распространённого протокола транспортного уровня: UDP.

> _**А вы знали?**  
> UDP — это максимально примитивный транспортный протокол. Он не отвечает вообще ни за что, кроме номеров портов (например, HTTP использует порт 80, HTTPS — 443, а DNS — 53). Он не устанавливает соединение с помощью рукопожатия и не обеспечивает надежность — потерянный пакет UDP не передаётся снова автоматически. Получается, что UDP работает на максимальной производительности — без ожидания рукопожатий и блокировок HoL. На практике UDP обычно используется для динамического трафика, который обновляется на высокой скорости и меньше зависит от потери пакетов, потому что недостающие данные всё равно быстро устаревают (например, онлайн-конференции или игры). Ещё он хорошо подходит для сценариев, где нужна минимальная задержка, например, поиск доменных имен DNS требует всего одной передачи туда и обратно._

Многие говорят, что HTTP/3 создан поверх UDP в целях производительности. Якобы HTTP/3 работает быстрее, потому что, как и UDP, не устанавливает соединение и не ждет повторной передачи пакетов. **Не верьте.** Мы уже сказали, что UDP используется протоколом QUIC, а значит и HTTP/3, в надежде, что так их будет проще развернуть, ведь UDP уже знают и используют почти все устройства в интернете.

Расположенный поверх UDP, **QUIC, по сути, реализует почти все функции, которые делают TCP таким эффективным и популярным (пусть и чуть более медленным) протоколом**. QUIC абсолютно надёжен — он использует [подтверждение полученных пакетов](https://www.rfc-editor.org/rfc/rfc9000.html#name-generating-acknowledgments) и [повторные передачи](https://www.rfc-editor.org/rfc/rfc9000.html#name-retransmission-of-informati), чтобы добрать то, что потерялось. QUIC по-прежнему устанавливает соединение и использует [сложную систему рукопожатий](https://www.rfc-editor.org/rfc/rfc9000.html#name-cryptographic-and-transport).

Наконец, QUIC использует механизмы [flow-control](https://www.rfc-editor.org/rfc/rfc9000.html#name-flow-control) и [congestion-control](https://www.rfc-editor.org/rfc/rfc9002.html), которые не дают отправителю перегрузить сеть или получателя, но замедляют TCP по сравнению «чистым» UDP. Правда QUIC реализует эти функции умнее и эффективнее. В нём собраны десятилетия опыта и лучших практик TCP и новые функции. Позже мы рассмотрим эти функции подробнее.

## Большие перемены

Почему QUIC лучше TCP? В чём разница? В QUIC есть несколько новых фич и возможностей (передача данных на 0-RTT, миграция соединений, больше устойчивости к потере пакетов и медленным сетям). Подробно мы поговорим о них в следующей части серии. Вкратце, все сводится к четырём основным изменениям:

1.  QUIC глубоко интегрирован с TLS.
2.  QUIC поддерживает несколько _независимых_ потоков байтов.
3.  QUIC использует идентификаторы соединений.
4.  QUIC использует фреймы.

А теперь подробнее о каждом пункте.

### Без TLS нет QUIC

Как мы уже говорили, протокол TLS ([Transport Layer Security](https://www.cloudflare.com/en-gb/learning/ssl/transport-layer-security-tls/)) отвечает за защиту и шифрование данных, отправленных через интернет. Когда вы используете HTTPS, открытый текст HTTP сначала шифруется TLS и только затем передается TCP.

> _**А вы знали?**  
> Вдаваться в технические детали TLS, к счастью, не обязательно. Достаточно знать, что шифрование выполняется с помощью сложных вычислений и очень больших простых чисел. Вся эта математика согласуется между клиентом и сервером во время отдельных криптографических рукопожатий, на которые, конечно, требуется время. В предыдущих версиях TLS (допустим, 1.2 и ниже) для этого требовалось два прохода туда-обратно. К счастью, новые версии TLS (сейчас последняя версия — 1.3) обходятся всего одним, потому что TLS 1.3 использует только математические алгоритмы, которые можно согласовать за одно рукопожатие. Это означает, что клиент может сразу догадаться, какие алгоритмы поддерживает сервер, не запрашивая и не получая список._

![image](https://habrastorage.org/r/w1560/webt/hy/ad/r3/hyadr31lydhynpwbdb8j5xl9bno.png)  
_Рукопожатия для TLS, TCP и QUIC ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f2240cb4-eb62-4054-ad19-0e72190e0a4f/connection-setup.png))_

На заре интернета шифрование трафика было ресурсозатратным. Считалось, что это нужно только в некоторых ситуациях. Исторически сложилось, что TLS стал полностью отдельным протоколом, который можно использовать поверх TCP _по желанию_. Поэтому мы разделяем HTTP (без TLS) и HTTPS (с TLS).

Со временем вектор развития интернета сместился в сторону принципа [«защищено по умолчанию»](https://blog.chromium.org/2021/03/a-safer-default-for-navigation-https.html). В теории HTTP/2 можно поместить поверх TCP без TLS (это даже определено в спецификации RFC как [открытый текст HTTP/2](https://tools.ietf.org/html/rfc7540#section-3.1)), но ни один популярный браузер не поддерживает этот режим. В каком-то смысле создатели браузеров решили усилить безопасность в ущерб производительности.

Раз теперь мы стремимся использовать TLS всегда (особенно для веб-трафика), неудивительно, что создатели QUIC вывели этот тренд на новый уровень. Вместо того, чтобы просто не определять режим открытого текста для HTTP/3, они решили встроить шифрование глубоко в сам QUIC. В первой версии QUIC от Google для этого использовалась кастомная настройка, а в стандартизированном QUIC есть сам TLS 1.3.

В итоге, по сути, **чёткие границы между протоколами в стеке стираются**, как видно на картинке выше. TLS 1.3 по-прежнему может работать независимо поверх TCP, но QUIC уже включает в себя TLS — невозможно использовать QUIC без TLS, поэтому QUIC (а значит и HTTP/3) всегда полностью зашифрован. Более того, QUIC шифрует почти все поля заголовков пакетов. Информация на транспортном уровне (номера пакетов, которые никогда не шифруются для TCP) больше недоступны для промежуточных точек (шифруются даже некоторые флаги заголовков пакетов).

![image](https://habrastorage.org/r/w1560/webt/sr/bi/ij/srbiijv-p7pyxto4oba04l9shsm.png)  
_В отличие от пары TCP + TLS, QUIC всегда шифрует метаданные на транспортном уровне в заголовке и полезной нагрузке пакета. (Примечание: размер полей нельзя менять.) ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fbf86b42-8f20-4b27-aea5-f1fc164b2683/tcp-vs-quic-packetization.png))_

Для этого QUIC сначала использует рукопожатие TLS 1.3 примерно так же, как TCP, чтобы установить математические параметры шифрования. Затем QUIC берёт инициативу и шифрует пакеты сам, а в модели TLS-over-TCP шифрованием занимается TLS. Это, вроде бы, незначительно отличие — большой шаг к постоянному шифрованию, которое применяется на ещё более низких уровнях протоколов.

Такой подход дает QUIC несколько преимуществ:

1.  **QUIC безопаснее для пользователей.**  
    Использовать QUIC с открытым текстом просто невозможно, поэтому у злоумышленников и перехватчиков меньше шансов. (Недавние исследования показали, [как опасен открытый текст в HTTP/2](https://labs.bishopfox.com/tech-blog/h2c-smuggling-request-smuggling-via-http/2-cleartext-h2c).)
2.  **С QUIC соединение устанавливается быстрее.**  
    В паре TLS-over-TCP обоим протоколам нужны отдельные рукопожатия, а QUIC объединяет транспортное и криптографическое рукопожатие в одно, экономя один цикл приема-передачи (см. картинку выше). Подробнее мы поговорим об этом во второй части.
3.  **QUIC проще развивать.**  
    Он полностью зашифрован, так что промежуточные устройства в сети не видят и не интерпретируют его работу, как с TCP. Поэтому новые версии QUIC будут работать так же легко, даже без обновления. Если мы захотим добавить в QUIC новые фичи, достаточно будет обновить конечное устройство, не трогая все промежуточные.

Шифрование требует больше ресурсов, и с этим связаны потенциальные недостатки нового протокола:

1.  **Многие сети будут неохотно разрешать QUIC.**  
    Компании захотят блокировать его на файрволах, потому что он мешает обнаруживать нежелательный трафик. Интернет-провайдеры и промежуточные сети будут его блокировать, потому что с ним сложнее определять разные метрики для диагностики, вроде средних задержек и процента потери пакетов. Это значит, что QUIC, скорее всего, никогда не будет использоваться повсюду. Подробнее об этом мы поговорим в третьей части.  
    1. **У QUIC высокие издержки на шифрование.**  
    QUIC шифрует через TLS каждый пакет по отдельности, а в TLS-over-TCP несколько пакетов шифруется за раз. Если трафик интенсивный, QUIC может работать медленнее (как мы увидим во второй части).  
    1. **QUIC приводит к централизации.**  
    Я часто слышу жалобы, что Google продвигает QUIC, чтобы получить полный доступ к данным и при этом не делиться ими ни с кем. Не соглашусь. Во-первых, QUIC скрывает от внешних наблюдателей не больше (и не меньше!) пользовательской информации (например, по каким URL вы переходите), чем TLS-over-TCP. В этом плане никаких изменений.

Во-вторых, хотя проект по QUIC затеяла Google, окончательные варианты протокола разработаны обширной командой Internet Engineering Task Force (IETF). QUIC IETF очень отличается от QUIC Google в техническом плане. Хотя в IETF и правда по большей части собрались ребята из крупных компаний, вроде Google и Facebook, и CDN, например, Cloudflare и Fastly. Из-за сложного устройства QUIC как раз у этих компаний будет достаточно знаний, чтобы правильно и эффективно развернуть HTTP/3 на практике. Возможно, это усилит централизацию, и это _действительно_ смущает.

> _**Личное мнение автора:**  
> Я не просто так пишу эти статьи и выступаю, рассказывая о технических деталях, — я хочу помочь людям разобраться в тонкостях и использовать протокол не через корпорации._

#### Выводы

QUIC **глубоко зашифрован по умолчанию**. Это хорошо не только для безопасности и конфиденциальности, но и в плане развёртывания и возможностей развития. Шифрование немного утяжеляет протокол, зато, например, позволяет быстрее устанавливать соединение.

### QUIC воспринимает несколько потоков байтов

Второе важное отличие TCP и QUIC связано с техническими нюансами, и его последствия мы подробно обсудим во второй части. Сейчас мы рассмотрим только общие аспекты.

> _**А вы знали?**  
> Даже простейшая веб-страница состоит из множества независимых файлов и ресурсов: HTML, CSS, JavaScript, изображения и т. д. Все эти файлы можно рассматривать как простые двоичные BLOB — набор нулей и единичек, которые интерпретирует браузер. При отправке этих файлов по сети мы передаем их не все сразу. Они делятся на небольшие фрагменты (обычно по 1400 байтов) и отправляются в отдельных пакетах. Поэтому каждый ресурс можно рассматривать как отдельный поток байтов, так как данные загружаются постепенно, потоком._

Для HTTP/1.1 все довольно просто, потому что **каждый файл получает собственное TCP-соединение** и загружается полностью. Например, для передачи файлов A, B и C у нас будет три TCP-соединения и три потока байтов — AAAA, BBBB, CCCC (каждая буква — отдельный пакет TCP). Это работает, но не слишком эффективно, потому что каждое соединение создает издержки.

На практике **браузеры накладывают ограничения** на количество соединений, а значит и на количество файлов, которые можно загрузить параллельно. Обычно это от 6 до 30 на загрузку одной страницы. Когда один файл загрузится, это соединение будет использоваться для следующего. Эти ограничения снижают производительность современных страниц, которые обычно включают куда больше 30 ресурсов.

HTTP/2 во многом был создан как раз для того, чтобы исправить эту проблему. Он не открывает по отдельному TCP-соединению для каждого файла, а загружает разные ресурсы через одно. Для этого используется **мультиплексирование потоков байтов**. Проще говоря, мы смешиваем данные из разных файлов при передаче. В нашем примере у нас будет одно TCP-соединение для трех файлов, и поток будет выглядеть примерно как AABBCCAABBCC (хотя [схем порядка может быть много](https://blog.cloudflare.com/better-http-2-prioritization-for-a-faster-web/)). Это выглядит довольно просто и работает неплохо, поэтому HTTP/2 работает не медленнее, чем HTTP/1.1, но требует меньше ресурсов.

Вот схема этого различия:

![image](https://habrastorage.org/r/w1560/webt/cx/8j/jw/cx8jjwovs7hcuu5epswckpu-iu8.png)  
_HTTP/1.1 не допускает мультиплексирование, в отличие от HTTP/2 и HTTP/3. ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/900ea8f0-3782-4505-b1b6-99ca2954bbce/multiplexing-basic.png))_

Правда, со стороны TCP есть проблема. Все-таки TCP очень старый и создан не только для загрузки веб-страниц, поэтому ни о каких A, B или C он не знает. С его точки зрения, **он передаёт один файл**, X, и ему нет дела, что XXXXXXXXXXXX на уровне HTTP на самом деле выглядит как AABBCCAABBCC. Обычно это и не важно, тем более что благодаря этому TCP довольно гибкий. Проблемы возникают, когда какой-нибудь пакет теряется.

Допустим, третий пакет TCP утерян (тот, где содержатся первые данные для файла B), а остальные данные доставлены. TCP в этом случае **заново передаёт новую копию потерянных данных** в новом пакете. Повторная передача требует времени (минимум один RTT). Вроде, не так и страшно, ведь у A и C ничего не потерялось, можно начать обработку, пока не придут данные для B. Так ведь?

К сожалению, не так. Логика повторной передачи обрабатывается на уровне TCP, а он о наших A, B и C даже не догадывается. TCP совершенно уверен, что потерялась часть X, а значит оставшиеся данные X обрабатывать нельзя, пока не дойдёт остальное. В двух словах, на уровне HTTP/2 мы знаем, что уже можно начать обработку A и C, но TCP об этом не подозревает, и обработка идет **медленнее, чем могла бы**. Это пример [блокировки HoL](https://calendar.perfplanet.com/2020/head-of-line-blocking-in-quic-and-http-3-the-details/).

**Решить проблему блокировки HoL на транспортном уровне было одной из главных целей QUIC**. В отличие от TCP, QUIC прекрасно понимает, что передаёт несколько _независимых_ потоков байтов. Он, понятно, не в курсе, что передаёт CSS, JavaScript и изображения, но знает, что это отдельные потоки. Поэтому QUIC обнаруживает потерю и восстанавливает пакеты для отдельных потоков.

В нашем сценарии он задержит только данные для потока B, а остальное как можно скорее передаст на уровень HTTP/3. (см. схему ниже) В теории это позволит повысить производительность. На практике есть некоторые нюансы. Но об этом во второй части.

![image](https://habrastorage.org/r/w1560/webt/kh/zd/5a/khzd5a0uj0mawm-gruebsmyjmok.png)  
_QUIC позволяет избавиться от блокировки HoL на уровне HTTP/3. ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7981cb82-395c-4484-8873-46fd92804b4d/hol-blocking-basic.png))_

Как видите, между TCP и QUIC есть фундаментальное различие. Заодно это во многом объясняет, почему нельзя просто запустить HTTP/2 поверх QUIC без изменений. Мы уже говорили, что HTTP/2 может запускать несколько потоков в одном TCP-соединении. В итоге у HTTP/2-over-QUIC получилось бы две разных и конкурирующих абстракции потоков, одна поверх другой.

Их примирение было бы очень сложным и ненадёжным, поэтому главное отличие HTTP/3 от HTTP/2 в том, что он **не содержит логику потоков и просто использует потоки QUIC**. Во второй части мы увидим, что у этого подхода есть свои последствия, которые касаются реализации server push, сжатия заголовков и приоритизации.

#### Выводы

TCP изначально не был предназначен для передачи нескольких независимых файлов в одном соединении. Поскольку веб-браузер требует как раз этого, мы много лет терпели разные проблемы. QUIC решает их, делая передачу нескольких потоков байтов основой транспортного уровня и обрабатывая потерю пакетов для каждого потока по отдельности.

### QUIC поддерживает миграцию соединений

Третье серьезное улучшение — в QUIC соединения могут дольше оставаться активными.

> _**А вы знали?**  
> Мы часто говорим о соединениях применительно к веб-протоколам. А что такое соединение? Обычно все говорят о TCP-соединении, когда между двумя конечными точками (допустим, браузером или клиентом и сервером) произошло рукопожатие. Поэтому часто (и не совсем справедливо) считается, что UDP не связан с соединением, ведь рукопожатия здесь нет. На самом деле, рукопожатие не так важно. Это просто отправка и получение нескольких пакетов в определённой форме. У него несколько целей, и главная из них — убедиться, что на том конце что-то есть, и оно готово и способно с нами взаимодействовать. Повторюсь: QUIC тоже выполняет рукопожатие, хотя работает поверх UDP, у которого рукопожатий нет._

Как пакеты прибывают в нужное место назначения? В интернете для маршрутизации пакетов между двумя конечными точками используются IP-адреса. Но недостаточно просто подключиться к IP-адресам телефона и сервера, потому что обоим устройствам нужна возможность запускать несколько сетевых программ одновременно.

Поэтому каждому соединению назначается **номер порта** на обоих устройствах, чтобы можно было различать эти соединения и приложения, которым они принадлежат. У серверных приложений обычно фиксированный номер порта в зависимости от функции (например, порты 80 и 443 для HTTP(S) и 53 — для DNS), а клиенты выбирают свои номера для каждого соединения отчасти рандомно.

Чтобы определить уникальное соединение между машинами и приложениями, мы используем четыре компонента: **IP-адрес клиента + порт клиента + IP-адрес сервера + порт сервера.**

В TCP соединения определяются этими четырьмя параметрами. Если один из них меняется, соединение разрывается и приходится устанавливать новое (с новым рукопожатием). Представьте задачу с парковкой. Вы используете смартфон в здании с Wi-Fi, и у вас есть IP-адрес этой сети.

Вы выходите на улицу, телефон переключается на сотовую сеть 4G, у которой, конечно, другой IP-адрес. Сервер видит, что TCP-пакет поступает с незнакомого IP (при этом оба порта и IP сервера не меняются). См. рисунок ниже.

![image](https://habrastorage.org/r/w1560/webt/-b/or/mm/-bormmrgnbjqmdyq_jool2qy5c0.png)  
_Задача с парковкой для TCP: клиент получает новый IP, сервер не воспринимает это как прежнее соединение. ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9413b221-47e9-427b-b958-b0e62fe7f681/1-migration-tcp.png))_

Как серверу узнать, что пакеты с нового IP относятся к тому же соединению? Как сервер понимает, что эти пакеты не связаны с _новым_ соединением от другого клиента в той же сотовой сети, который случайно выбрал тот же клиентский порт (такое вполне может случиться)? К сожалению, он никак этого не сможет понять.

TCP был изобретен задолго до того, как появились сотовые сети и смартфоны, у него нет механизма, с помощью которого клиент мог бы сообщить серверу, что сменил IP. Там нет даже способа «закрыть» соединение, потому что команда сброса или завершения, отправленная по соединению со старыми четырьмя параметрами, даже не дойдет до клиента. Поэтому на практике при каждой смене сети **существующие TCP-соединения больше нельзя использовать**.

Нужно новое рукопожатие TCP (и, возможно, TLS), чтобы установить новое соединение. В зависимости от протокола на уровне приложений придется перезапустить некоторые действия. Например, если вы загружали большой файл по HTTP, возможно, придется повторно запросить файл (например, если сервер не поддерживает [запросы на диапазон](https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests)). Ещё один пример — веб-конференция в реальном времени будет ненадолго прерываться при смене сетей.

Для смены одного из четырех параметров могут быть и другие причины (например, [повторная привязка NAT](https://blog.cloudflare.com/the-road-to-quic/#onenattobringthemallandinthedarknessbindthem)). Подробнее об этом мы поговорим во второй части.

Перезапуск TCP-соединений мешает работе (приходится ждать новых рукопожатий, перезапускать загрузку, снова устанавливать контекст). Чтобы решить проблему, QUIC вводит новую концепцию — **идентификатор соединения CID**. Каждому соединению между двумя конечными точками помимо четырёх параметров присваивается уникальный номер.

Поскольку CID определяется на транспортном уровне в самом QUIC, он не меняется при перемещении между сетями. См. рисунок ниже. Для этого CID указывается перед каждым пакетом QUIC наряду с IP-адресами и портами. Это один из немногих компонентов в заголовке пакета QUIC, который не зашифрован.

![image](https://habrastorage.org/r/w1560/webt/sx/ic/tj/sxictjjwesnksvtd7zm98_f3tri.png)  
_QUIC использует CID, чтобы соединение сохранялось после смены сети. ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e6ae0ec1-3b85-49a9-9707-ee21ce5b02b3/2-migration-single-cid.png))_

При таком раскладе, даже если один из четырех параметров изменится, серверу и клиенту **нужно будет просто посмотреть на CID**, чтобы узнать старое соединение и дальше использовать его. Новое рукопожатие можно опустить, состояние загрузки сохранится. Обычно это называется _миграцией соединения_. В теории это позволит повысить производительность, но тут тоже есть свои нюансы (подробности — во второй части).

У CID, конечно, есть недостатки. Например, если мы будем использовать один CID, хакерам будет очень просто отслеживать пользователей по сетям и хотя бы приблизительно определять, где они находятся. Чтобы избежать этих проблем, **QUIC меняет CID при каждом переходе в новую сеть**.

Да, знаю, я только что сказал, что CID будет одинаковым в разных сетях. Но это я упростил, конечно. На самом деле клиент и сервер договариваются об **общем списке рандомно генерируемых CID**, которые связаны с одним и тем же соединением.

Например, обе стороны знают, что CID K, C и D относятся к соединению X. Допустим, клиент помечает пакеты K в Wi-Fi, а затем использует C в 4G. Списки полностью зашифрованы в QUIC, так что никто со стороны не поймет, что K и C относятся к X, а клиент и сервер будут это знать, чтобы поддерживать соединение.

![image](https://habrastorage.org/r/w1560/webt/oc/an/d_/ocand_opv250ktzy0e1sknilmb0.png)  
_QUIC использует несколько согласованных CID, чтобы пользователя нельзя было отследить. ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/715f189e-4ae6-4c4c-8db8-9fd8170049d8/3-migration-multi-cid.png))_

Все ещё сложнее, потому что у клиентов и серверов будут разные списки CID, которые они выбрали сами (так же, как у них есть разные номера портов). Это нужно для поддержки маршрутизации и балансировки нагрузки в масштабных системах (подробнее об этом в третьей части).

#### Выводы

При использовании TCP соединения определяются по **четырём параметрам**, которые могут меняться при смене сети конечной точки. Приходится тратить время на перезапуск таких соединений. QUIC добавляет ещё один параметр — идентификатор соединения CID. В QUIC клиент и сервер знают, какой CID с каким соединением связан, чтобы соединение можно было не разрывать.

### Гибкость и простота развития QUIC

Наконец, QUIC специально создан так, чтобы его было легко развивать. Это связано с несколькими особенностями протокола. Во-первых, QUIC почти полностью зашифрован, так что, если мы захотим развернуть его новую версию, обновлять нужно будет только конечные точки (клиенты и серверы), а не промежуточные устройства. На это, конечно, тоже потребуется время, но речь идёт о месяцах, а не годах.

Во-вторых, в отличие от TCP, QUIC не использует один фиксированный заголовок пакета для отправки всех метаданных протокола. Вместо этого QUIC использует короткие заголовки пакета и [разные фреймы](https://www.rfc-editor.org/rfc/rfc9000.html#name-frames-and-frame-types) (такие миниатюрные специализированные пакеты) в полезной нагрузке пакета, чтобы передать дополнительную информацию. Есть, например, фрейм `ACK` (acknowledgement — подтверждение), `NEW_CONNECTION_ID` (для миграции соединения) или `STREAM` (для передачи данных). См. рисунок ниже.

Это сделано для оптимизации, потому что не каждый пакет содержит все возможные метаданные (заголовки пакетов в TCP весили лишние байты). Ещё один плюс фреймов — в будущем можно будет легко добавлять в QUIC их новые разновидности. Например, [фрейм](https://datatracker.ietf.org/doc/html/draft-ietf-quic-datagram-02) `DATAGRAM`, которые позволяет отправлять ненадёжные данные по зашифрованному QUIC-соединению.

![image](https://habrastorage.org/r/w1560/webt/lh/ej/x0/lhejx0indeasz8u7nkuxag_b9-e.png)  
_QUIC использует отдельные фреймы для отправки метаданных вместо большого фиксированного заголовка пакета. ([исходное изображение](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/88c76a7a-2752-4e5b-a829-290cd4951af3/quic-framing.png))_

В-третьих, QUIC использует кастомное расширение TLS для передачи [параметров транспорта](https://www.rfc-editor.org/rfc/rfc9000.html#name-transport-parameters), чтобы клиент и сервер могли выбирать конфигурацию для QUIC-соединения. То есть они могут согласовать используемые функции (например, нужно ли разрешить миграцию соединения, какие расширения поддерживаются и т. д.) и передавать важные параметры по умолчанию для некоторых механизмов (например, максимальный поддерживаемый размер пакета, лимиты flow-control). В стандарте QUIC определён [длинный список](https://www.rfc-editor.org/rfc/rfc9000.html#name-transport-parameter-definit) таких параметров, но можно определять и новые, что делает протокол ещё более гибким.

Наконец, сам QUIC этого не требует, но сейчас большинство реализаций выполняется в пользовательском пространстве (а не в пространстве ядра, как у TCP). Подробнее об этом мы поговорим во второй части, но по сути это означает, что нам будет гораздо проще экспериментировать с вариациями реализаций и расширениями QUIC и развёртывать их, чем это было с TCP.

#### Выводы

Пока что QUIC ещё находится в процессе стандартизации, но текущую реализацию следует считать QUIC version 1, и это указано в [Request For Comments (RFC)](https://www.rfc-editor.org/rfc/rfc9000.html#name-overview). Вторая версия не за горами. Помимо прочего, QUIC позволяет легко определять расширения, так что вариантов применения будет ещё больше.